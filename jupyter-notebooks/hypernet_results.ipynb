{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importing Useful Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.nn.functional import softmax\n",
        "import torch.nn.init as init"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Device Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Preprocessing \n",
        "### Normalizing Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "938c5f11836348b981eaf316d111f5a0",
            "a2f0a348616642f3b519c22099a1e23d",
            "496b26c60d884b8da77ac2688175685a",
            "3bf2c2ae5ab04a099e00c48e69942c45",
            "19a6ba679ada46ddb001ac7948769bd2",
            "4be9dcad296540b58c06a6d424cc3927",
            "44201e2d372f4a6b9e9fb89f8cefdc98",
            "03d575b27a544319b8469962c2cd0d88",
            "5273ae074cfe42a08f9618a62f409d35",
            "1e1e3835314f4155a1218944e1c1cd14",
            "7332d4dca2524802b009dc3d8a16be6b"
          ]
        },
        "id": "dAhujv6RPGkJ",
        "outputId": "c8d8cf25-26cc-4934-a885-dee0e1396dc7"
      },
      "outputs": [],
      "source": [
        "normalize_transform = transforms.Normalize(\n",
        "        mean=torch.tensor([125.29552899, 122.99125831, 113.90624687]) / 256,\n",
        "        std=torch.tensor([62.9836127, 62.04402182, 66.63918649]) / 256\n",
        "    )\n",
        "transform = transforms.Compose([\n",
        "    transforms.Pad(4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.ToTensor(),\n",
        "    normalize_transform])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize_transform])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Datasets and DataLoader\n",
        "Default setup on CIFAR10 dataset, for running on CIFAR100 change CIFAR10 to CIFAR100 on train_dataset and test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                             train=True, \n",
        "                                             transform=transform,\n",
        "                                             download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                            train=False, \n",
        "                                            transform=transform_test)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=128, \n",
        "                                           shuffle=False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=128, \n",
        "                                          shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining Resnets\n",
        "Implemented Resnet structures namely Resnet2, Resnet6, Resnet10, Resnet14, Resnet20 and Resnet56"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exZ9dbvLPWoW"
      },
      "outputs": [],
      "source": [
        "\n",
        "def conv3x3(in_channels, out_channels, stride=1):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
        "                     stride=stride, padding=1, bias=False)\n",
        "    \n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels,track_running_stats=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(out_channels, out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels,track_running_stats=False)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, layers, block = ResidualBlock, num_classes=256):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = conv3x3(3, 16)\n",
        "        self.bn = nn.BatchNorm2d(16,track_running_stats=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
        "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
        "        self.avg_pool = nn.AvgPool2d(8)\n",
        "        self.fc = nn.Linear(64, num_classes, bias = True)\n",
        "        \n",
        "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels,track_running_stats=False))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "            out = self.conv(x)\n",
        "            out = self.bn(out)\n",
        "            out = self.relu(out)\n",
        "            out = self.layer1(out)\n",
        "            out = self.layer2(out)\n",
        "            out = self.layer3(out)\n",
        "            out = self.avg_pool(out)\n",
        "            out = out.view(out.size(0), -1)\n",
        "            out = self.fc(out)\n",
        "            return out\n",
        "\n",
        "class ResNet2(nn.Module):\n",
        "    def __init__(self, block = ResidualBlock, num_classes=256):\n",
        "        super(ResNet2, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = conv3x3(3, 16)\n",
        "        self.bn = nn.BatchNorm2d(16,track_running_stats=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.avg_pool = nn.AvgPool2d(32)\n",
        "        self.fc = nn.Linear(16, num_classes, bias = True)\n",
        "        self.apply(_weights_init)\n",
        "        \n",
        "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels,track_running_stats=False))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "            out = self.conv(x)\n",
        "            out = self.bn(out)\n",
        "            out = self.relu(out)\n",
        "            out = self.avg_pool(out)\n",
        "            out = out.view(out.size(0), -1)\n",
        "            out = self.fc(out)\n",
        "            return out\n",
        "\n",
        "class ResNet6(nn.Module):\n",
        "    def __init__(self, block = ResidualBlock, num_classes=256):\n",
        "        super(ResNet6, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = conv3x3(3, 16)\n",
        "        self.bn = nn.BatchNorm2d(16,track_running_stats=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, 1)\n",
        "        self.layer2 = self.make_layer(block, 32, 1, 2)\n",
        "        self.avg_pool = nn.AvgPool2d(16)\n",
        "        self.fc = nn.Linear(32, num_classes, bias = True)\n",
        "        \n",
        "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels,track_running_stats=False))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "            out = self.conv(x)\n",
        "            out = self.bn(out)\n",
        "            out = self.relu(out)\n",
        "            out = self.layer1(out)\n",
        "            out = self.layer2(out)\n",
        "            out = self.avg_pool(out)\n",
        "            out = out.view(out.size(0), -1)\n",
        "            out = self.fc(out)\n",
        "            return out\n",
        "\n",
        "class ResNet10(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet10, self).__init__()\n",
        "        self.ResNet = ResNet([2,1,1])\n",
        "    def forward(self,x):\n",
        "        out = self.ResNet(x)\n",
        "        return out\n",
        "\n",
        "class ResNet14(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet14, self).__init__()\n",
        "        self.ResNet = ResNet([2,2,2])\n",
        "    def forward(self,x):\n",
        "        out = self.ResNet(x)\n",
        "        return out\n",
        "\n",
        "class ResNet20(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet20, self).__init__()\n",
        "        self.ResNet = ResNet([3,3,3])\n",
        "    def forward(self,x):\n",
        "        out = self.ResNet(x)\n",
        "        return out\n",
        "\n",
        "class ResNet56(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet56, self).__init__()\n",
        "        self.ResNet = ResNet([9,9,9])\n",
        "    def forward(self,x):\n",
        "        out = self.ResNet(x)\n",
        "        return out"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deterministic Networks\n",
        "Implementation of baseline network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DeterministicNetwork(nn.Module):\n",
        "    def __init__(self, base, num_classes=10):\n",
        "        super(DeterministicNetwork, self).__init__()\n",
        "        self.base = base\n",
        "        self.fc = nn.Linear(256,num_classes, bias = True)\n",
        "    def forward(self,x):\n",
        "        out = self.base(x)\n",
        "        out = self.fc(out)\n",
        "        return softmax(out, dim = 1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generator Network\n",
        "Implemented G<sub>e</sub>, G<sub>h</sub> from 1-D Resnet6 blocks and combined them for Generator network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def conv3x31d(in_channels, out_channels, stride=1):\n",
        "    return nn.Conv1d(in_channels, out_channels, kernel_size=3, \n",
        "                     stride=stride, padding=1, bias=False)\n",
        "    \n",
        "class ResidualBlock1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock1d, self).__init__()\n",
        "        self.conv1 = conv3x31d(in_channels, out_channels, stride)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels,track_running_stats=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x31d(out_channels, out_channels)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels,track_running_stats=False)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "class Ge(nn.Module):\n",
        "    def __init__(self, block = ResidualBlock1d , num_classes=256):\n",
        "        super(Ge, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = conv3x31d(2, 16)\n",
        "        self.bn = nn.BatchNorm1d(16,track_running_stats=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, 1)\n",
        "        self.layer2 = self.make_layer(block, 32, 1, 2)\n",
        "        self.avg_pool = nn.AvgPool1d(128)\n",
        "        self.fc = nn.Linear(32, num_classes, bias = True)\n",
        "\n",
        "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                conv3x31d(self.in_channels, out_channels, stride=stride),\n",
        "                nn.BatchNorm1d(out_channels,track_running_stats=False))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "class Gh(nn.Module):\n",
        "    def __init__(self, block = ResidualBlock1d , num_classes=10):\n",
        "        super(Gh, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = conv3x31d(3, 16)\n",
        "        self.bn = nn.BatchNorm1d(16,track_running_stats=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, 1)\n",
        "        self.layer2 = self.make_layer(block, 32, 1, 2)\n",
        "        self.avg_pool = nn.AvgPool1d(128)\n",
        "        self.fc1 = nn.Linear(32, 256*num_classes, bias = True)\n",
        "        self.fc2 = nn.Linear(32,num_classes, bias = True)\n",
        "\n",
        "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                conv3x31d(self.in_channels, out_channels, stride=stride),\n",
        "                nn.BatchNorm1d(out_channels,track_running_stats=False))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out1 = self.fc1(out)\n",
        "        out2 = self.fc2(out)\n",
        "        return out1, out2\n",
        "\n",
        "class GeneratorNetwork(nn.Module):\n",
        "    def __init__(self,num_classes=10):\n",
        "        super(GeneratorNetwork, self).__init__()\n",
        "        self.Ge = Ge()\n",
        "        self.num_classes = num_classes\n",
        "        self.Gh = Gh(num_classes=num_classes)\n",
        "        self.fc = nn.Linear(num_classes,256,bias=True)\n",
        "    def forward(self,y,z1,z2,num_samples = 1):\n",
        "        y = self.fc(y).view(num_samples,1,256)\n",
        "        temp = self.Ge(torch.cat((z1,y),axis = 1))\n",
        "        temp = temp.unsqueeze(1).repeat(1, 1, 1)\n",
        "        W,b = self.Gh(torch.cat((z2,temp,y),axis=1))\n",
        "        return W.view(num_samples,256,self.num_classes),b.view(num_samples,1,self.num_classes)\n",
        "\n",
        "class CFNN(nn.Module):\n",
        "    def __init__(self, base,num_classes=10 ):\n",
        "        super(CFNN, self).__init__()\n",
        "        self.base = base\n",
        "        self.generator = GeneratorNetwork(num_classes = num_classes)\n",
        "        self.num_classes = num_classes\n",
        "    \n",
        "    def sampler(self, num_samples): \n",
        "        m = torch.distributions.categorical.Categorical(torch.zeros(self.num_classes) + 1/self.num_classes)\n",
        "        x = m.sample([int(num_samples)])\n",
        "        return nn.functional.one_hot(x,self.num_classes).type(torch.float32)\n",
        "\n",
        "    def forward(self,x,num_samples = 1):\n",
        "        out = self.base(x)\n",
        "        W,b = self.generator(self.sampler(num_samples).to(device),torch.rand(num_samples,1,256).to(device),torch.rand(num_samples,1,256).to(device),num_samples)\n",
        "        out = softmax(torch.matmul(out,W) - b, dim=2)\n",
        "        out = torch.mean(out,axis = 0)\n",
        "        return out\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mean Weights\n",
        "Mean weights ablation study."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class mean_weights(nn.Module):\n",
        "  def __init__(self, base, model, num_classes):\n",
        "    super(mean_weights, self).__init__()\n",
        "    self.generator = model\n",
        "    self.base = base\n",
        "    self.num_classes = num_classes\n",
        "\n",
        "  def sampler(self, num_samples): \n",
        "        m = torch.distributions.categorical.Categorical(torch.zeros(self.num_classes) + 1/self.num_classes)\n",
        "        x = m.sample([int(num_samples)])\n",
        "        return nn.functional.one_hot(x,self.num_classes).type(torch.float32)\n",
        "\n",
        "  def forward(self,x, num_samples = 25):\n",
        "    out = self.base(x)\n",
        "    mW,mb = self.generator(self.sampler(num_samples).to(device),torch.rand(num_samples,1,256).to(device),torch.rand(num_samples,1,256).to(device),num_samples)\n",
        "    mW = torch.tensor(mW)\n",
        "    mb = torch.tensor(mb)\n",
        "    mW = torch.mean(mW,axis = 0)\n",
        "    mb = torch.mean(mb,axis = 0)\n",
        "    out = torch.matmul(out,mW) - mb\n",
        "    return softmax(out, dim = 1)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Frozen Net\n",
        "Experimental Study."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Linear Layer\n",
        "class frozen_net_resnet0(nn.Module):\n",
        "    def __init__(self, base, frozen, num_classes=10 ):\n",
        "        super(frozen_net_resnet0, self).__init__()\n",
        "        self.base = base\n",
        "        self.frozen_net = frozen\n",
        "        self.num_classes = num_classes\n",
        "    \n",
        "    def forward(self,x):\n",
        "        out = self.base(x)\n",
        "        out = out.repeat(1,1,1)\n",
        "        out = out.permute(1,0,2)\n",
        "        out = self.frozen_net(out)\n",
        "        out = softmax(out, dim=1)\n",
        "        return out\n",
        "\n",
        "class frozen_net_resnet6(nn.Module):\n",
        "  def __init__(self, block = ResidualBlock1d , num_classes=10):\n",
        "        super(frozen_net_resnet6, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = conv3x31d(1, 16)\n",
        "        self.bn = nn.BatchNorm1d(16,track_running_stats=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, 1)\n",
        "        self.layer2 = self.make_layer(block, 32, 1, 2)\n",
        "        self.avg_pool = nn.AvgPool1d(128)\n",
        "        self.fc = nn.Linear(32, num_classes, bias = True)\n",
        "\n",
        "  def make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                conv3x31d(self.in_channels, out_channels, stride=stride),\n",
        "                nn.BatchNorm1d(out_channels,track_running_stats=False))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "      out = self.conv(x)\n",
        "      out = self.bn(out)\n",
        "      out = self.relu(out)\n",
        "      out = self.layer1(out)\n",
        "      out = self.layer2(out)\n",
        "      out = self.avg_pool(out)\n",
        "      out = out.view(out.size(0), -1)\n",
        "      out = self.fc(out)\n",
        "      return out\n",
        "\n",
        "class frozen_net_resnet2(nn.Module):\n",
        "  def __init__(self, block = ResidualBlock1d , num_classes=10):\n",
        "        super(frozen_net_resnet2, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = conv3x31d(1, 16)\n",
        "        self.bn = nn.BatchNorm1d(16,track_running_stats=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.avg_pool = nn.AvgPool1d(256)\n",
        "        self.fc = nn.Linear(16, num_classes, bias = True)\n",
        "\n",
        "  def forward(self, x):\n",
        "      out = self.conv(x)\n",
        "      out = self.bn(out)\n",
        "      out = self.relu(out)\n",
        "      out = self.avg_pool(out)\n",
        "      out = out.view(out.size(0), -1)\n",
        "      out = self.fc(out)\n",
        "      return out\n",
        "\n",
        "class frozen_net_resnet4(nn.Module):\n",
        "  def __init__(self, block = ResidualBlock1d , num_classes=10):\n",
        "        super(frozen_net_resnet4, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = conv3x31d(1, 16)\n",
        "        self.bn = nn.BatchNorm1d(16,track_running_stats=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, 1)\n",
        "        self.avg_pool = nn.AvgPool1d(256)\n",
        "        self.fc = nn.Linear(16, num_classes, bias = True)\n",
        "\n",
        "  def make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                conv3x31d(self.in_channels, out_channels, stride=stride),\n",
        "                nn.BatchNorm1d(out_channels,track_running_stats=False))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "      out = self.conv(x)\n",
        "      out = self.bn(out)\n",
        "      out = self.relu(out)\n",
        "      out = self.layer1(out)\n",
        "      out = self.avg_pool(out)\n",
        "      out = out.view(out.size(0), -1)\n",
        "      out = self.fc(out)\n",
        "      return out"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experimental Study \n",
        "Similar to Frozen Net, increasing the depth of embedding layer, for repeating n times change `depth = n` in init argument, training will be similar to frozen net only `frozen_net_resnet0` will be replaced by `neural_network()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class neural_network(nn.Module):\n",
        "  def __init__(self, base, depth = 2, num_classes = 10):\n",
        "    super(neural_network, self).__init__()\n",
        "    self.base = base\n",
        "    self.nn = self.Make_network(depth, num_channels = 256)\n",
        "    self.fc = nn.Linear(256,num_classes,bias=True)\n",
        "\n",
        "  def Make_network(self, depth, num_channels =  256): \n",
        "        layers = []\n",
        "        for i in range(depth):\n",
        "            layers.append(nn.Linear(num_channels,num_channels,bias=True))\n",
        "            layers.append(nn.ReLU())\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.base(x)\n",
        "    out = self.nn(out)\n",
        "    out = self.fc(out)\n",
        "    return softmax(out, dim = 1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AP7LGm0uPXbn"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "weight_decay = 0.005\n",
        "num_epochs = 200\n",
        "num_samples = 25"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining Loss and Learning Rate Schedulers\n",
        "Defined `NLLLoss` and Cosine Learning-Rate scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dQfdd72XPZaM"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "from torch.nn import NLLLoss"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining Model Training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5_qA-sthPbio"
      },
      "outputs": [],
      "source": [
        "#Training of the model\n",
        "def Training(model,samples = None):\n",
        "    Loss = NLLLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr,momentum = 0.9,weight_decay=0.005)\n",
        "    scheduler = CosineAnnealingWarmRestarts(optimizer,T_0 = num_epochs,eta_min = 0)\n",
        "    # optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum = 0.9, weight_decay = 0.005)\n",
        "    total_step = len(train_loader)\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            if samples:\n",
        "                output = model(images,samples)\n",
        "                loss = Loss(output, labels) \n",
        "            else:\n",
        "                output = model(images) \n",
        "            loss = Loss(torch.log(output+1e-015), labels)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad() \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if (i+1) % 100 == 0:\n",
        "                print (\" Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
        "                       .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "        scheduler.step()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining Model Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2HvnHk3rhnDC"
      },
      "outputs": [],
      "source": [
        "def Testing(model,samples=None):\n",
        "    model.eval()\n",
        "    mean_accuracy = 0\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            if samples:\n",
        "                output = model(images, samples) \n",
        "            else:\n",
        "                output = model(images)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        \n",
        "    \n",
        "    \n",
        "    return 100*correct/total"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For defining Baseline Network define it as shown below\n",
        "Default on CIFAR10 dataset, dataset can be changed from CIFAR10 to CIFAR100 by changing `10` to `100` in argument of DeterministicNetwork, and Resnet structure can be changed by changing suffix of Resnet6 to Resnet10(or others) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resnet 6 / CIFAR 10\n",
        "baseline_resnet = DeterministicNetwork(ResNet6(), 10).to(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For defining Hypernet define it as shown below\n",
        "Dataset can be changed from CIFAR10 to CIFAR100 by changing `10` to `100` in argument of CFNN similarly, and Resnet structure can be changed by changing suffix of Resnet6 to Resnet10(or others) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resnet 6 / CIFAR 10\n",
        "CFNN_resnet = CFNN(ResNet6(), 10).to(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training of Baseline Network can be done as shown below "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Training(baseline_resnet)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training of HyperNet can be done as shown below "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Training(CFNN_resnet)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing of Baseline Network and HyperNet can be done as "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Testing(baseline_resnet)\n",
        "Testing(CFNN_resnet)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For defining Frozen Network define it as shown below\n",
        "For running on different Frozen Resnet change suffix of resnet {0(linear layer) ,4, 2, 6}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "frozen_net = frozen_net_resnet0(CFNN_resnet.base,frozen_net_resnet4()).to(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training of Frozen Network can be done as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "frozen_net.base.requires_grad = False\n",
        "Training(frozen_net)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing of Frozen Network can be done as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Testing(frozen_net)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For defining Mean Weights define it as below\n",
        "For changing dataset from CIFAR10 to CIFAR100 change 10 to 100 in argument of mean_weights_Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_Resnet = CFNN_resnet.base\n",
        "mean_weights_Resnet = mean_weights(mean_Resnet, CFNN_resnet,10).to(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For testing Mean Weights Ablation Study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Testing(mean_weights_Resnet)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03d575b27a544319b8469962c2cd0d88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19a6ba679ada46ddb001ac7948769bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e1e3835314f4155a1218944e1c1cd14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bf2c2ae5ab04a099e00c48e69942c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e1e3835314f4155a1218944e1c1cd14",
            "placeholder": "​",
            "style": "IPY_MODEL_7332d4dca2524802b009dc3d8a16be6b",
            "value": " 170498071/170498071 [00:01&lt;00:00, 89237029.90it/s]"
          }
        },
        "44201e2d372f4a6b9e9fb89f8cefdc98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "496b26c60d884b8da77ac2688175685a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03d575b27a544319b8469962c2cd0d88",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5273ae074cfe42a08f9618a62f409d35",
            "value": 170498071
          }
        },
        "4be9dcad296540b58c06a6d424cc3927": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5273ae074cfe42a08f9618a62f409d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7332d4dca2524802b009dc3d8a16be6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "938c5f11836348b981eaf316d111f5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2f0a348616642f3b519c22099a1e23d",
              "IPY_MODEL_496b26c60d884b8da77ac2688175685a",
              "IPY_MODEL_3bf2c2ae5ab04a099e00c48e69942c45"
            ],
            "layout": "IPY_MODEL_19a6ba679ada46ddb001ac7948769bd2"
          }
        },
        "a2f0a348616642f3b519c22099a1e23d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4be9dcad296540b58c06a6d424cc3927",
            "placeholder": "​",
            "style": "IPY_MODEL_44201e2d372f4a6b9e9fb89f8cefdc98",
            "value": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
